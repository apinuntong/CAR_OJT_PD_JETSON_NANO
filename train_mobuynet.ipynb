{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "from keras_segmentation.models.unet import mobilenet_unet\n",
    "from keras_segmentation.models.unet import unet_mini\n",
    "from keras_segmentation.models.unet import mobilenet_unet\n",
    "from keras_segmentation.models.segnet import mobilenet_segnet\n",
    "from keras_segmentation.models.segnet import segnet\n",
    "from keras_segmentation.models.segnet import vgg_segnet\n",
    "from keras_segmentation.models.fcn import fcn_32_mobilenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = mobilenet_segnet(n_classes=6 ,  input_height=128, input_width=128, encoder_level=2 )\n",
    "# model = vgg_segnet(n_classes=5 ,  input_height=128, input_width=128  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 24)        648       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 64, 64, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 24)        216       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 64, 64, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 48)        1152      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 64, 64, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 48)        432       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 96)        4608      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 96)        864       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 96)        9216      \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 96)        864       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 192)       18432     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 192)       1728      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 192)       36864     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 192)         1728      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 384)         73728     \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 10, 10, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 512)         1769984   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 34, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 66, 66, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 6)         3462      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4096, 6)           0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4096, 6)           0         \n",
      "=================================================================\n",
      "Total params: 3,483,222\n",
      "Trainable params: 3,477,942\n",
      "Non-trainable params: 5,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 50/1207 [00:00<00:02, 491.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [00:02<00:00, 483.32it/s]\n",
      " 18%|█▊        | 50/281 [00:00<00:00, 496.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying val dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:00<00:00, 476.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 47s 92ms/step - loss: 0.2284 - accuracy: 0.9266 - val_loss: 0.1030 - val_accuracy: 0.9572\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10298, saving model to output2/mobilenetV1_75_segnet_tongtest.01\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 43s 84ms/step - loss: 0.1184 - accuracy: 0.9573 - val_loss: 0.0883 - val_accuracy: 0.9636\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10298 to 0.08834, saving model to output2/mobilenetV1_75_segnet_tongtest.02\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 43s 84ms/step - loss: 0.0989 - accuracy: 0.9625 - val_loss: 0.0901 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08834\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 44s 85ms/step - loss: 0.0868 - accuracy: 0.9661 - val_loss: 0.0852 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08834 to 0.08522, saving model to output2/mobilenetV1_75_segnet_tongtest.04\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 44s 85ms/step - loss: 0.0813 - accuracy: 0.9679 - val_loss: 0.0927 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08522\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 44s 85ms/step - loss: 0.0748 - accuracy: 0.9698 - val_loss: 0.0662 - val_accuracy: 0.9648\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08522 to 0.06617, saving model to output2/mobilenetV1_75_segnet_tongtest.06\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 44s 85ms/step - loss: 0.0713 - accuracy: 0.9713 - val_loss: 0.1151 - val_accuracy: 0.9558\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06617\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0666 - accuracy: 0.9729 - val_loss: 0.0786 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06617\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0628 - accuracy: 0.9742 - val_loss: 0.0866 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06617\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0607 - accuracy: 0.9750 - val_loss: 0.1408 - val_accuracy: 0.9645\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06617\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0570 - accuracy: 0.9765 - val_loss: 0.0852 - val_accuracy: 0.9594\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06617\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0554 - accuracy: 0.9771 - val_loss: 0.1728 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06617\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0531 - accuracy: 0.9779 - val_loss: 0.0715 - val_accuracy: 0.9627\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06617\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0513 - accuracy: 0.9787 - val_loss: 0.0920 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06617\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0495 - accuracy: 0.9793 - val_loss: 0.2777 - val_accuracy: 0.9648\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06617\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0481 - accuracy: 0.9800 - val_loss: 0.1260 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06617\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0471 - accuracy: 0.9804 - val_loss: 0.0965 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06617\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0457 - accuracy: 0.9809 - val_loss: 0.0574 - val_accuracy: 0.9634\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06617 to 0.05741, saving model to output2/mobilenetV1_75_segnet_tongtest.18\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0450 - accuracy: 0.9813 - val_loss: 0.1475 - val_accuracy: 0.9618\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05741\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0437 - accuracy: 0.9817 - val_loss: 0.2149 - val_accuracy: 0.9643\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05741\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0426 - accuracy: 0.9822 - val_loss: 0.1235 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05741\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0418 - accuracy: 0.9825 - val_loss: 0.0965 - val_accuracy: 0.9626\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05741\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0416 - accuracy: 0.9826 - val_loss: 0.0797 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05741\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0402 - accuracy: 0.9833 - val_loss: 0.0695 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05741\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0394 - accuracy: 0.9835 - val_loss: 0.0850 - val_accuracy: 0.9644\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05741\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0384 - accuracy: 0.9839 - val_loss: 0.1022 - val_accuracy: 0.9644\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05741\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0383 - accuracy: 0.9840 - val_loss: 0.1507 - val_accuracy: 0.9648\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05741\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0371 - accuracy: 0.9845 - val_loss: 0.1825 - val_accuracy: 0.9634\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05741\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0363 - accuracy: 0.9848 - val_loss: 0.1502 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05741\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0365 - accuracy: 0.9848 - val_loss: 0.1197 - val_accuracy: 0.9625\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05741\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0356 - accuracy: 0.9851 - val_loss: 0.0837 - val_accuracy: 0.9659\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05741\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0350 - accuracy: 0.9853 - val_loss: 0.1137 - val_accuracy: 0.9655\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05741\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0348 - accuracy: 0.9855 - val_loss: 0.0914 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05741\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0338 - accuracy: 0.9859 - val_loss: 0.1001 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05741\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0331 - accuracy: 0.9862 - val_loss: 0.0673 - val_accuracy: 0.9651\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05741\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0330 - accuracy: 0.9862 - val_loss: 0.1422 - val_accuracy: 0.9651\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05741\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 0.0909 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05741\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0318 - accuracy: 0.9868 - val_loss: 0.0605 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05741\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0311 - accuracy: 0.9870 - val_loss: 0.1109 - val_accuracy: 0.9652\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05741\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0309 - accuracy: 0.9871 - val_loss: 0.0661 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05741\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 0.1491 - val_accuracy: 0.9643\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05741\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0302 - accuracy: 0.9874 - val_loss: 0.0870 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05741\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0296 - accuracy: 0.9877 - val_loss: 0.2423 - val_accuracy: 0.9659\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05741\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 45s 87ms/step - loss: 0.0288 - accuracy: 0.9880 - val_loss: 0.1041 - val_accuracy: 0.9635\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05741\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0292 - accuracy: 0.9878 - val_loss: 0.0970 - val_accuracy: 0.9646\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05741\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0282 - accuracy: 0.9883 - val_loss: 0.0923 - val_accuracy: 0.9642\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05741\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0281 - accuracy: 0.9883 - val_loss: 0.1422 - val_accuracy: 0.9663\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05741\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0274 - accuracy: 0.9886 - val_loss: 0.1610 - val_accuracy: 0.9662\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05741\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 0.1301 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05741\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0268 - accuracy: 0.9888 - val_loss: 0.1757 - val_accuracy: 0.9662\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05741\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0267 - accuracy: 0.9889 - val_loss: 0.1061 - val_accuracy: 0.9655\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05741\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0263 - accuracy: 0.9890 - val_loss: 0.0759 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.05741\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0264 - accuracy: 0.9890 - val_loss: 0.1209 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.05741\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 45s 88ms/step - loss: 0.0257 - accuracy: 0.9893 - val_loss: 0.0935 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.05741\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0253 - accuracy: 0.9895 - val_loss: 0.1012 - val_accuracy: 0.9659\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.05741\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0251 - accuracy: 0.9896 - val_loss: 0.1447 - val_accuracy: 0.9650\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.05741\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0249 - accuracy: 0.9897 - val_loss: 0.1009 - val_accuracy: 0.9672\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05741\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0246 - accuracy: 0.9898 - val_loss: 0.1347 - val_accuracy: 0.9645\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.05741\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0246 - accuracy: 0.9898 - val_loss: 0.1099 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.05741\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0239 - accuracy: 0.9901 - val_loss: 0.1076 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.05741\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0235 - accuracy: 0.9903 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.05741\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0232 - accuracy: 0.9904 - val_loss: 0.1210 - val_accuracy: 0.9671\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.05741\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0232 - accuracy: 0.9904 - val_loss: 0.1614 - val_accuracy: 0.9660\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.05741\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0228 - accuracy: 0.9905 - val_loss: 0.0959 - val_accuracy: 0.9672\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.05741\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0224 - accuracy: 0.9907 - val_loss: 0.0959 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.05741\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 45s 87ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 0.0821 - val_accuracy: 0.9665\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.05741\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0223 - accuracy: 0.9908 - val_loss: 0.1448 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05741\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0222 - accuracy: 0.9908 - val_loss: 0.1278 - val_accuracy: 0.9658\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.05741\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0219 - accuracy: 0.9910 - val_loss: 0.1448 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05741\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0216 - accuracy: 0.9911 - val_loss: 0.1146 - val_accuracy: 0.9652\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.05741\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0212 - accuracy: 0.9912 - val_loss: 0.0894 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05741\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 0.1222 - val_accuracy: 0.9659\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.05741\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 0.0883 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05741\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.0825 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05741\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0205 - accuracy: 0.9915 - val_loss: 0.7877 - val_accuracy: 0.9665\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05741\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0201 - accuracy: 0.9917 - val_loss: 0.1212 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05741\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0197 - accuracy: 0.9918 - val_loss: 0.1187 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05741\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0198 - accuracy: 0.9919 - val_loss: 0.0983 - val_accuracy: 0.9652\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05741\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0195 - accuracy: 0.9920 - val_loss: 0.1237 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05741\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0191 - accuracy: 0.9921 - val_loss: 0.1431 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05741\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 0.2945 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05741\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 0.1829 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05741\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 0.0861 - val_accuracy: 0.9655\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.05741\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 0.1477 - val_accuracy: 0.9662\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05741\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 0.1562 - val_accuracy: 0.9669\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05741\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 45s 87ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.1807 - val_accuracy: 0.9658\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05741\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0176 - accuracy: 0.9927 - val_loss: 0.0851 - val_accuracy: 0.9670\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05741\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0176 - accuracy: 0.9928 - val_loss: 0.2035 - val_accuracy: 0.9672\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05741\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0173 - accuracy: 0.9929 - val_loss: 0.1361 - val_accuracy: 0.9663\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05741\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 0.2772 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05741\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 0.1081 - val_accuracy: 0.9658\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05741\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0172 - accuracy: 0.9929 - val_loss: 0.1282 - val_accuracy: 0.9671\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05741\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.2920 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05741\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.1079 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05741\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 0.1824 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05741\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0162 - accuracy: 0.9933 - val_loss: 0.1457 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05741\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0160 - accuracy: 0.9935 - val_loss: 0.1361 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05741\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0160 - accuracy: 0.9935 - val_loss: 0.1052 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05741\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 44s 87ms/step - loss: 0.0159 - accuracy: 0.9935 - val_loss: 0.1081 - val_accuracy: 0.9670\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05741\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 44s 86ms/step - loss: 0.0156 - accuracy: 0.9936 - val_loss: 0.3195 - val_accuracy: 0.9672\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05741\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"dataset_p9AL/images_prepped_train1000\\\\\",\n",
    "    train_annotations = \"dataset_p9AL/annotations_prepped_train1000\\\\\",\n",
    "    checkpoints_path = \"output2/mobilenetV1_75_segnet_tongtest\" , epochs=100,\n",
    "    validate=True,\n",
    "    val_images=\"dataset_p9AL/images_prepped_test1000\\\\\",\n",
    "    val_annotations=\"dataset_p9AL/annotations_prepped_test1000\\\\\",\n",
    "#     auto_resume_checkpoint=True,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"output\\\\test0_9803.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('output2/mobilenetV1_75_segnet_tongtest.18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.67361861766389\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "tong1 = time.time()\n",
    "out = model.predict_segmentation(\n",
    "    inp=\"dataset_p9AL/images_prepped_test1000\\\\imageOP411.jpg\",\n",
    ")\n",
    "tong2 = time.time()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)\n",
    "print(1/(tong2 - tong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.predict import predict,model_from_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights  output\\tongtest.h5.4\n"
     ]
    }
   ],
   "source": [
    "modeltong = model_from_checkpoint_path('output\\\\tongtest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-2859665189a5>\", line 3, in <module>\n",
      "    out = modeltong.predict_segmentation(\n",
      "NameError: name 'modeltong' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\contrib\\__init__.py\", line 48, in <module>\n",
      "    from tensorflow.contrib import estimator\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\contrib\\estimator\\__init__.py\", line 30, in <module>\n",
      "    from tensorflow_estimator.contrib import estimator\n",
      "ModuleNotFoundError: No module named 'tensorflow_estimator.contrib'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modeltong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tong1 = time.time()\n",
    "out = modeltong.predict_segmentation(\n",
    "    inp=\"dataset_p9AL/images_prepped_test1000\\\\image9949.jpg\",\n",
    ")\n",
    "tong2 = time.time()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)\n",
    "print(1/(tong2 - tong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_point(imag_1234):\n",
    "    xxxcccv =0 \n",
    "    xxxcccv_b =0 \n",
    "    px_x = 0\n",
    "    y_pol =0\n",
    "    path_geny = np.zeros((12,2))\n",
    "    for i in range(12) :\n",
    "        px_x = 0\n",
    "        prx = imag_1234[y_pol:y_pol+1][0:64]\n",
    "        for c in range(len(prx[0])) :\n",
    "            xxxcccv = prx[0][c]\n",
    "            if xxxcccv == 4 and xxxcccv_b == 3 :\n",
    "                px_x = c\n",
    "            xxxcccv_b = xxxcccv\n",
    "        \n",
    "        if px_x != 0 :\n",
    "            _pts = np.float32([[[px_x*2.5, y_pol*1.875]]])\n",
    "            _dst = cv2.perspectiveTransform(_pts, perspective_M)\n",
    "            _dst = _dst[0][0]\n",
    "\n",
    "            path_geny[i][0] =_dst[0]\n",
    "            path_geny[i][1] =_dst[1]\n",
    "        else :\n",
    "            path_geny[i][0] =0\n",
    "            path_geny[i][1] =0\n",
    "        y_pol = y_pol+5\n",
    "    return  path_geny \n",
    "\n",
    "# tong555  = find_target_point(pr)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(prx)\n",
    "# print(tong555.astype('int'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1.234567\n",
    "y = \"{:0.2f}\".format(x)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
